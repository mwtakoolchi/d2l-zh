{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00d510a",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Custom Layers\n",
    "\n",
    "One factor behind deep learning's success\n",
    "is the availability of a wide range of layers\n",
    "that can be composed in creative ways\n",
    "to design architectures suitable\n",
    "for a wide variety of tasks.\n",
    "For instance, researchers have invented layers\n",
    "specifically for handling images, text,\n",
    "looping over sequential data,\n",
    "and\n",
    "performing dynamic programming.\n",
    "Sooner or later, you will need\n",
    "a layer that does not exist yet in the deep learning framework.\n",
    "In these cases, you must build a custom layer.\n",
    "In this section, we show you how.\n",
    "\n",
    "# 自定义层\n",
    "\n",
    "深度学习成功的一个重要因素是可以用创造性的方式组合各种层，从而设计出适用于多种任务的架构。例如，研究者发明了专门用于处理图像、文本、序列数据以及执行动态编程的层。很快你就会遇到需要深度学习框架中尚不存在的层的情况。这时你必须构建自定义层。本节将展示如何实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe58dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:01.509651Z",
     "iopub.status.busy": "2023-08-18T07:08:01.509057Z",
     "iopub.status.idle": "2023-08-18T07:08:04.377633Z",
     "shell.execute_reply": "2023-08-18T07:08:04.376649Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df619f5f",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## (**Layers without Parameters**)\n",
    "\n",
    "To start, we construct a custom layer\n",
    "that does not have any parameters of its own.\n",
    "This should look familiar if you recall our\n",
    "introduction to modules in :numref:`sec_model_construction`.\n",
    "The following `CenteredLayer` class simply\n",
    "subtracts the mean from its input.\n",
    "To build it, we simply need to inherit\n",
    "from the base layer class and implement the forward propagation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2c97f",
   "metadata": {},
   "source": [
    "## （无参数层）\n",
    "\n",
    "我们首先构造一个没有任何参数的自定义层。\n",
    "如果回忆一下 :numref:`sec_model_construction` 对模块的介绍，\n",
    "这应该看起来很眼熟。\n",
    "下面的`CenteredLayer`类要从其输入中减去均值。\n",
    "要构建它，我们只需继承基础层类并实现前向传播函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d65b3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.381848Z",
     "iopub.status.busy": "2023-08-18T07:08:04.381127Z",
     "iopub.status.idle": "2023-08-18T07:08:04.385729Z",
     "shell.execute_reply": "2023-08-18T07:08:04.384893Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05996a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiCenteredLayer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac64027",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "Let's verify that our layer works as intended by feeding some data through it.\n",
    "\n",
    "通过输入数据验证我们的层是否按预期工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1de0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.389305Z",
     "iopub.status.busy": "2023-08-18T07:08:04.388618Z",
     "iopub.status.idle": "2023-08-18T07:08:04.415777Z",
     "shell.execute_reply": "2023-08-18T07:08:04.414999Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.tensor([1.0, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc149180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000,  0.5000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = ChiCenteredLayer()\n",
    "layer(torch.tensor([2.0,3.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6622b5",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "We can now [**incorporate our layer as a component\n",
    "in constructing more complex models.**]\n",
    "\n",
    "我们现在可以[**将我们的层作为组件整合到构建更复杂的模型中。**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4d0d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.419366Z",
     "iopub.status.busy": "2023-08-18T07:08:04.418636Z",
     "iopub.status.idle": "2023-08-18T07:08:04.423168Z",
     "shell.execute_reply": "2023-08-18T07:08:04.422372Z"
    },
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07a8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_chi = nn.Sequential(nn.LazyLinear(128), ChiCenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8f878",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "As an extra sanity check, we can send random data\n",
    "through the network and check that the mean is in fact 0.\n",
    "Because we are dealing with floating point numbers,\n",
    "we may still see a very small nonzero number\n",
    "due to quantization.  \n",
    "作为额外的合理性检查，我们可以向网络发送随机数据并验证均值确实为0。由于处理的是浮点数，可能会因量化误差导致出现极小的非零值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed37bf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.426435Z",
     "iopub.status.busy": "2023-08-18T07:08:04.425877Z",
     "iopub.status.idle": "2023-08-18T07:08:04.435077Z",
     "shell.execute_reply": "2023-08-18T07:08:04.434263Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3132e-10, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9728bc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4703e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_y = net_chi(torch.rand(5,50))\n",
    "chi_y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12f65d",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "## [**Layers with Parameters**]\n",
    "\n",
    "Now that we know how to define simple layers,\n",
    "let's move on to defining layers with parameters\n",
    "that can be adjusted through training.\n",
    "We can use built-in functions to create parameters, which\n",
    "provide some basic housekeeping functionality.\n",
    "In particular, they govern access, initialization,\n",
    "sharing, saving, and loading model parameters.\n",
    "This way, among other benefits, we will not need to write\n",
    "custom serialization routines for every custom layer.\n",
    "\n",
    "Now let's implement our own version of the  fully connected layer.\n",
    "Recall that this layer requires two parameters,\n",
    "one to represent the weight and the other for the bias.\n",
    "In this implementation, we bake in the ReLU activation as a default.\n",
    "This layer requires two input arguments: `in_units` and `units`, which\n",
    "denote the number of inputs and outputs, respectively.\n",
    "\n",
    "## [**带参数的层**]\n",
    "\n",
    "现在我们已经掌握了如何定义简单层，接下来我们转向定义具有可训练参数的层。这些参数可以通过内置函数创建，这些函数提供了基础管理功能，包括参数访问、初始化、共享、保存和加载等。这种设计使我们无需为每个自定义层编写序列化例程。\n",
    "\n",
    "接下来我们实现一个自定义的全连接层。该层需要两个参数：权重矩阵和偏置向量。在本实现中，我们将ReLU激活函数设为默认选项。该层接收两个输入参数：`in_units`（输入维度）和`units`（输出维度）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1d0471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.438468Z",
     "iopub.status.busy": "2023-08-18T07:08:04.437819Z",
     "iopub.status.idle": "2023-08-18T07:08:04.442897Z",
     "shell.execute_reply": "2023-08-18T07:08:04.442113Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da0e929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiLinear(nn.Module):\n",
    "    def __init__(self, in_units, units) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd90da",
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "Next, we instantiate the `MyLinear` class\n",
    "and access its model parameters.\n",
    "\n",
    "接下来我们实例化`MyLinear`类并访问其模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "583b57bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.446339Z",
     "iopub.status.busy": "2023-08-18T07:08:04.445672Z",
     "iopub.status.idle": "2023-08-18T07:08:04.451742Z",
     "shell.execute_reply": "2023-08-18T07:08:04.450954Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1445, -0.7544, -0.1263],\n",
       "        [-0.4094, -0.7189,  0.0768],\n",
       "        [-0.7084,  1.5421, -0.3582],\n",
       "        [ 1.2273,  1.2663, -0.3321],\n",
       "        [ 1.2490,  1.8487, -0.6465]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac6578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-1.1973,  0.4563,  1.3573], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_linear = ChiLinear(5,3)\n",
    "chi_linear.bias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e73443",
   "metadata": {
    "origin_pos": 34
   },
   "source": [
    "We can [**directly carry out forward propagation calculations using custom layers.**]\n",
    "\n",
    "我们可以[直接使用自定义层执行前向传播计算。]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809379ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.455153Z",
     "iopub.status.busy": "2023-08-18T07:08:04.454506Z",
     "iopub.status.idle": "2023-08-18T07:08:04.460481Z",
     "shell.execute_reply": "2023-08-18T07:08:04.459703Z"
    },
    "origin_pos": 36,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6911, 0.0697, 1.6517],\n",
       "        [1.0260, 1.4526, 1.4564]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1f739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 1.9289],\n",
       "        [0.0927, 1.7660, 0.9098],\n",
       "        [0.0000, 0.0000, 2.7838]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_linear(torch.rand(3,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88c97e",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "We can also (**construct models using custom layers.**)\n",
    "Once we have that we can use it just like the built-in fully connected layer.\n",
    "\n",
    "我们也可以[**使用自定义层构建模型**]。定义完成后，可以像使用内置全连接层一样调用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e6a244a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:08:04.463848Z",
     "iopub.status.busy": "2023-08-18T07:08:04.463293Z",
     "iopub.status.idle": "2023-08-18T07:08:04.469711Z",
     "shell.execute_reply": "2023-08-18T07:08:04.468891Z"
    },
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.7059],\n",
       "        [8.4347]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "308a0df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56.7026,  0.0000, 17.5639],\n",
       "        [69.1863,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_net = nn.Sequential(ChiLinear(128,256), ChiLinear(256,3))\n",
    "chi_net(torch.rand(2,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c879a",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "## Summary\n",
    "\n",
    "We can design custom layers via the basic layer class. This allows us to define flexible new layers that behave differently from any existing layers in the library.\n",
    "Once defined, custom layers can be invoked in arbitrary contexts and architectures.\n",
    "Layers can have local parameters, which can be created through built-in functions.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Design a layer that takes an input and computes a tensor reduction,\n",
    "   i.e., it returns $y_k = \\sum_{i, j} W_{ijk} x_i x_j$.\n",
    "1. Design a layer that returns the leading half of the Fourier coefficients of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665add30",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层，其行为与库中现有的任何层不同。\n",
    "一旦定义完成，自定义层可以在任意上下文中和架构中被调用。\n",
    "层可以拥有通过内置函数创建的局部参数。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 设计一个层，使其接受输入并计算张量缩减，即返回$y_k = \\sum_{i, j} W_{ijk} x_i x_j$。\n",
    "1. 设计一个层，使其返回数据傅里叶系数的前半部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e07457",
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/59)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
