{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2331ea",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Pooling\n",
    ":label:`sec_pooling`\n",
    "\n",
    "In many cases our ultimate task asks some global question about the image,\n",
    "e.g., *does it contain a cat?* Consequently, the units of our final layer \n",
    "should be sensitive to the entire input.\n",
    "By gradually aggregating information, yielding coarser and coarser maps,\n",
    "we accomplish this goal of ultimately learning a global representation,\n",
    "while keeping all of the advantages of convolutional layers at the intermediate layers of processing.\n",
    "The deeper we go in the network,\n",
    "the larger the receptive field (relative to the input)\n",
    "to which each hidden node is sensitive. Reducing spatial resolution \n",
    "accelerates this process, \n",
    "since the convolution kernels cover a larger effective area. \n",
    "\n",
    "Moreover, when detecting lower-level features, such as edges\n",
    "(as discussed in :numref:`sec_conv_layer`),\n",
    "we often want our representations to be somewhat invariant to translation.\n",
    "For instance, if we take the image `X`\n",
    "with a sharp delineation between black and white\n",
    "and shift the whole image by one pixel to the right,\n",
    "i.e., `Z[i, j] = X[i, j + 1]`,\n",
    "then the output for the new image `Z` might be vastly different.\n",
    "The edge will have shifted by one pixel.\n",
    "In reality, objects hardly ever occur exactly at the same place.\n",
    "In fact, even with a tripod and a stationary object,\n",
    "vibration of the camera due to the movement of the shutter\n",
    "might shift everything by a pixel or so\n",
    "(high-end cameras are loaded with special features to address this problem).\n",
    "\n",
    "This section introduces *pooling layers*,\n",
    "which serve the dual purposes of\n",
    "mitigating the sensitivity of convolutional layers to location\n",
    "and of spatially downsampling representations.\n",
    "\n",
    "# 池化\n",
    ":label:`sec_pooling`\n",
    "\n",
    "在许多情况下，我们的最终任务会提出关于图像的全局性问题，例如*图像中是否包含猫？* 因此，最终层的单元需要对整个输入敏感。通过逐步聚合信息，生成越来越粗糙的特征图，我们实现了最终学习全局表示的目标，同时保留了卷积层在中间处理层的所有优势。随着网络深度的增加，每个隐藏节点对输入的感受野（相对输入而言）会变得更大。降低空间分辨率可以加速这一过程，因为卷积核覆盖的有效区域会更大。\n",
    "\n",
    "此外，在检测低级特征（如边缘，如 :numref:`sec_conv_layer` 节所述）时，我们通常希望表示对平移具有一定的不变性。例如，假设我们有一张黑白分界清晰的图像 `X`，若将整个图像向右平移一个像素（即 `Z[i, j] = X[i, j + 1]`），新图像 `Z` 的输出可能会大不相同。边缘会移动一个像素的位置。现实中，物体几乎不会完全出现在同一位置。即使使用三脚架固定拍摄静止物体，快门的运动引起的相机振动也可能导致所有内容偏移几个像素（高端相机配备了特殊功能来解决此问题）。\n",
    "\n",
    "本节将介绍*池化层*，它的双重作用是：\n",
    "1. 降低卷积层对位置的敏感性\n",
    "2. 对空间表征进行下采样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d2fdaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:17.921163Z",
     "iopub.status.busy": "2023-08-18T07:09:17.920885Z",
     "iopub.status.idle": "2023-08-18T07:09:21.120887Z",
     "shell.execute_reply": "2023-08-18T07:09:21.117937Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910798d",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## Maximum Pooling and Average Pooling\n",
    "\n",
    "Like convolutional layers, *pooling* operators\n",
    "consist of a fixed-shape window that is slid over\n",
    "all regions in the input according to its stride,\n",
    "computing a single output for each location traversed\n",
    "by the fixed-shape window (sometimes known as the *pooling window*).\n",
    "However, unlike the cross-correlation computation\n",
    "of the inputs and kernels in the convolutional layer,\n",
    "the pooling layer contains no parameters (there is no *kernel*).\n",
    "Instead, pooling operators are deterministic,\n",
    "typically calculating either the maximum or the average value\n",
    "of the elements in the pooling window.\n",
    "These operations are called *maximum pooling* (*max-pooling* for short)\n",
    "and *average pooling*, respectively.\n",
    "\n",
    "*Average pooling* is essentially as old as CNNs. The idea is akin to \n",
    "downsampling an image. Rather than just taking the value of every second (or third) \n",
    "pixel for the lower resolution image, we can average over adjacent pixels to obtain \n",
    "an image with better signal-to-noise ratio since we are combining the information \n",
    "from multiple adjacent pixels. *Max-pooling* was introduced in \n",
    ":citet:`Riesenhuber.Poggio.1999` in the context of cognitive neuroscience to describe \n",
    "how information aggregation might be aggregated hierarchically for the purpose \n",
    "of object recognition; there already was an earlier version in speech recognition :cite:`Yamaguchi.Sakamoto.Akabane.ea.1990`. In almost all cases, max-pooling, as it is also referred to, \n",
    "is preferable to average pooling. \n",
    "\n",
    "In both cases, as with the cross-correlation operator,\n",
    "we can think of the pooling window\n",
    "as starting from the upper-left of the input tensor\n",
    "and sliding across it from left to right and top to bottom.\n",
    "At each location that the pooling window hits,\n",
    "it computes the maximum or average\n",
    "value of the input subtensor in the window,\n",
    "depending on whether max or average pooling is employed.\n",
    "\n",
    "\n",
    "![Max-pooling with a pooling window shape of $2\\times 2$. The shaded portions are the first output element as well as the input tensor elements used for the output computation: $\\max(0, 1, 3, 4)=4$.](../img/pooling.svg)\n",
    ":label:`fig_pooling`\n",
    "\n",
    "The output tensor in :numref:`fig_pooling`  has a height of 2 and a width of 2.\n",
    "The four elements are derived from the maximum value in each pooling window:\n",
    "\n",
    "$$\n",
    "\\max(0, 1, 3, 4)=4,\\\\\n",
    "\\max(1, 2, 4, 5)=5,\\\\\n",
    "\\max(3, 4, 6, 7)=7,\\\\\n",
    "\\max(4, 5, 7, 8)=8.\\\\\n",
    "$$\n",
    "\n",
    "More generally, we can define a $p \\times q$ pooling layer by aggregating over \n",
    "a region of said size. Returning to the problem of edge detection, \n",
    "we use the output of the convolutional layer\n",
    "as input for $2\\times 2$ max-pooling.\n",
    "Denote by `X` the input of the convolutional layer input and `Y` the pooling layer output. \n",
    "Regardless of whether or not the values of `X[i, j]`, `X[i, j + 1]`, \n",
    "`X[i+1, j]` and `X[i+1, j + 1]` are different,\n",
    "the pooling layer always outputs `Y[i, j] = 1`.\n",
    "That is to say, using the $2\\times 2$ max-pooling layer,\n",
    "we can still detect if the pattern recognized by the convolutional layer\n",
    "moves no more than one element in height or width.\n",
    "\n",
    "In the code below, we (**implement the forward propagation\n",
    "of the pooling layer**) in the `pool2d` function.\n",
    "This function is similar to the `corr2d` function\n",
    "in :numref:`sec_conv_layer`.\n",
    "However, no kernel is needed, computing the output\n",
    "as either the maximum or the average of each region in the input.\n",
    "\n",
    "## 最大池化与平均池化\n",
    "\n",
    "与卷积层类似，*池化*算子也由一个固定形状的窗口组成，该窗口根据其步幅在输入的所有区域上滑动。池化窗口每次滑动所覆盖的位置会计算一个输出值（该窗口有时也称为*池化窗口*）。然而，与卷积层中输入和核的互相关计算不同，池化层不包含参数（没有*核*）。池化运算是确定性的，通常计算池化窗口中元素的最大值或平均值。这些操作分别称为*最大池化*（简称max-pooling）和*平均池化*（average pooling）。\n",
    "\n",
    "*平均池化*的历史几乎与CNN一样悠久。其思想类似于图像下采样。与直接取每隔一个（或三个）像素作为低分辨率图像不同，我们可以通过对相邻像素取平均值来获得信噪比更高的图像，因为这样结合了多个相邻像素的信息。*最大池化*由 :citet:`Riesenhuber.Poggio.1999` 在认知神经科学的背景下引入，用于描述如何通过层次化信息聚合实现物体识别；更早的版本已出现在语音识别领域 :cite:`Yamaguchi.Sakamoto.Akabane.ea.1990`。在几乎所有情况下，最大池化都比平均池化更优。\n",
    "\n",
    "与互相关运算符类似，池化窗口从输入张量的左上角开始，从左到右、从上到下滑动。在池化窗口到达的每个位置，它会根据池化类型（最大池化或平均池化）计算窗口内输入子张量的最大值或平均值。\n",
    "\n",
    "\n",
    "![使用 $2\\times 2$ 池化窗口的最大池化。阴影部分是第一个输出元素，以及用于计算该输出的输入张量元素：$\\max(0, 1, 3, 4)=4$。](../img/pooling.svg)\n",
    ":label:`fig_pooling`\n",
    "\n",
    ":numref:`fig_pooling` 中的输出张量高度和宽度均为2。这四个元素由每个池化窗口内的最大值产生：\n",
    "\n",
    "$$\n",
    "\\max(0, 1, 3, 4)=4,\\\\\n",
    "\\max(1, 2, 4, 5)=5,\\\\\n",
    "\\max(3, 4, 6, 7)=7,\\\\\n",
    "\\max(4, 5, 7, 8)=8.\\\\\n",
    "$$\n",
    "\n",
    "更一般地，我们可以通过聚合 $p \\times q$ 大小的区域来定义池化层。回到边缘检测问题，我们将卷积层的输出作为 $2\\times 2$ 最大池化的输入。用 `X` 表示卷积层的输入，`Y` 表示池化层的输出。无论 `X[i, j]`、`X[i, j + 1]`、`X[i+1, j]` 和 `X[i+1, j + 1]` 的值是否不同，池化层始终输出 `Y[i, j] = 1`。也就是说，使用 $2\\times 2$ 最大池化层，我们仍然可以检测到卷积层识别的模式在高度和宽度上移动不超过一个元素的情况。\n",
    "\n",
    "在下面的代码中，我们（**实现池化层的前向传播**）函数 `pool2d`。该函数与 :numref:`sec_conv_layer` 中的 `corr2d` 函数类似，但无需核参数，其输出为输入每个区域的最大值或平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96766e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.128118Z",
     "iopub.status.busy": "2023-08-18T07:09:21.125997Z",
     "iopub.status.idle": "2023-08-18T07:09:21.134886Z",
     "shell.execute_reply": "2023-08-18T07:09:21.134029Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed269bb",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "We can construct the input tensor `X` in :numref:`fig_pooling` to [**validate the output of the two-dimensional max-pooling layer**].\n",
    "\n",
    "我们可以通过构建 :numref:`fig_pooling` 中的输入张量 `X` 来 [**验证二维最大池化层的输出**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b4900e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.138488Z",
     "iopub.status.busy": "2023-08-18T07:09:21.137876Z",
     "iopub.status.idle": "2023-08-18T07:09:21.172221Z",
     "shell.execute_reply": "2023-08-18T07:09:21.171406Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cc5a0",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "Also, we can experiment with (**the average pooling layer**).\n",
    "\n",
    "此外，我们可以尝试（**使用平均池化层**）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11c48a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.176127Z",
     "iopub.status.busy": "2023-08-18T07:09:21.175534Z",
     "iopub.status.idle": "2023-08-18T07:09:21.182982Z",
     "shell.execute_reply": "2023-08-18T07:09:21.182182Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615a7fa",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "## [**Padding and Stride**]\n",
    "\n",
    "As with convolutional layers, pooling layers\n",
    "change the output shape.\n",
    "And as before, we can adjust the operation to achieve a desired output shape\n",
    "by padding the input and adjusting the stride.\n",
    "We can demonstrate the use of padding and strides\n",
    "in pooling layers via the built-in two-dimensional max-pooling layer from the deep learning framework.\n",
    "We first construct an input tensor `X` whose shape has four dimensions,\n",
    "where the number of examples (batch size) and number of channels are both 1.\n",
    "\n",
    "## [**填充与步幅**]\n",
    "\n",
    "与卷积层类似，池化层也会改变输出形状。和之前一样，我们可以通过填充输入和调整步幅来获得所需的输出形状。我们可以通过深度学习框架内置的二维最大池化层来演示池化层中填充和步幅的使用。首先构造一个形状为四维的输入张量 `X`，其中样本数（批量大小）和通道数都为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a75748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.186318Z",
     "iopub.status.busy": "2023-08-18T07:09:21.185761Z",
     "iopub.status.idle": "2023-08-18T07:09:21.192079Z",
     "shell.execute_reply": "2023-08-18T07:09:21.191209Z"
    },
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf92f2",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "Since pooling aggregates information from an area, (**deep learning frameworks default to matching pooling window sizes and stride.**) For instance, if we use a pooling window of shape `(3, 3)`\n",
    "we get a stride shape of `(3, 3)` by default.\n",
    "\n",
    "由于池化操作会对区域内的信息进行聚合，（**深度学习框架默认将池化窗口大小与步幅设为相同值**）。例如，当使用形状为 `(3, 3)` 的池化窗口时，默认获得的步幅形状也是 `(3, 3)`。\n",
    "```</think></think>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5a44fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.195859Z",
     "iopub.status.busy": "2023-08-18T07:09:21.195043Z",
     "iopub.status.idle": "2023-08-18T07:09:21.201204Z",
     "shell.execute_reply": "2023-08-18T07:09:21.200350Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "# Pooling has no model parameters, hence it needs no initialization\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b269e",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "Needless to say, [**the stride and padding can be manually specified**] to override framework defaults if required.\n",
    "\n",
    "[**如有需要，可以手动指定步幅与填充参数**] 来覆盖框架的默认设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d00279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.205184Z",
     "iopub.status.busy": "2023-08-18T07:09:21.204617Z",
     "iopub.status.idle": "2023-08-18T07:09:21.212541Z",
     "shell.execute_reply": "2023-08-18T07:09:21.211728Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d210c2b",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "Of course, we can specify an arbitrary rectangular pooling window with arbitrary height and width respectively, as the example below shows.\n",
    "\n",
    "当然，我们可以如以下示例所示，分别指定任意矩形池化窗口的高度和宽度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692dd76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.216067Z",
     "iopub.status.busy": "2023-08-18T07:09:21.215497Z",
     "iopub.status.idle": "2023-08-18T07:09:21.223134Z",
     "shell.execute_reply": "2023-08-18T07:09:21.222025Z"
    },
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfec538",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## Multiple Channels\n",
    "\n",
    "When processing multi-channel input data,\n",
    "[**the pooling layer pools each input channel separately**],\n",
    "rather than summing the inputs up over channels\n",
    "as in a convolutional layer.\n",
    "This means that the number of output channels for the pooling layer\n",
    "is the same as the number of input channels.\n",
    "Below, we will concatenate tensors `X` and `X + 1`\n",
    "on the channel dimension to construct an input with two channels.\n",
    "\n",
    "## 多通道\n",
    "\n",
    "在处理多通道输入数据时，\n",
    "[**池化层会分别对每个输入通道进行池化操作**]，\n",
    "而不是像卷积层那样在通道维度上对输入进行汇总。\n",
    "这意味着池化层的输出通道数与输入通道数相同。\n",
    "接下来，我们将在通道维度上将张量 `X` 和 `X + 1` 进行拼接，\n",
    "从而构造一个具有两个通道的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92088c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.228126Z",
     "iopub.status.busy": "2023-08-18T07:09:21.227566Z",
     "iopub.status.idle": "2023-08-18T07:09:21.234142Z",
     "shell.execute_reply": "2023-08-18T07:09:21.233286Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67de37",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "As we can see, the number of output channels is still two after pooling.\n",
    "\n",
    "如我们所见，经过池化操作后输出通道数仍为两个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "956b3d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:21.238030Z",
     "iopub.status.busy": "2023-08-18T07:09:21.237494Z",
     "iopub.status.idle": "2023-08-18T07:09:21.243944Z",
     "shell.execute_reply": "2023-08-18T07:09:21.243167Z"
    },
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688b5f9",
   "metadata": {
    "origin_pos": 42
   },
   "source": [
    "## Summary\n",
    "\n",
    "Pooling is an exceedingly simple operation. It does exactly what its name indicates, aggregate results over a window of values. All convolution semantics, such as strides and padding apply in the same way as they did previously. Note that pooling is indifferent to channels, i.e., it leaves the number of channels unchanged and it applies to each channel separately. Lastly, of the two popular pooling choices, max-pooling is preferable to average pooling, as it confers some degree of invariance to output. A popular choice is to pick a pooling window size of $2 \\times 2$ to quarter the spatial resolution of output. \n",
    "\n",
    "Note that there are many more ways of reducing resolution beyond pooling. For instance, in stochastic pooling :cite:`Zeiler.Fergus.2013` and fractional max-pooling :cite:`Graham.2014` aggregation is combined with randomization. This can slightly improve the accuracy in some cases. Lastly, as we will see later with the attention mechanism, there are more refined ways of aggregating over outputs, e.g., by using the alignment between a query and representation vectors. \n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Implement average pooling through a convolution. \n",
    "1. Prove that max-pooling cannot be implemented through a convolution alone. \n",
    "1. Max-pooling can be accomplished using ReLU operations, i.e., $\\textrm{ReLU}(x) = \\max(0, x)$.\n",
    "    1. Express $\\max (a, b)$ by using only ReLU operations.\n",
    "    1. Use this to implement max-pooling by means of convolutions and ReLU layers. \n",
    "    1. How many channels and layers do you need for a $2 \\times 2$ convolution? How many for a $3 \\times 3$ convolution?\n",
    "1. What is the computational cost of the pooling layer? Assume that the input to the pooling layer is of size $c\\times h\\times w$, the pooling window has a shape of $p_\\textrm{h}\\times p_\\textrm{w}$ with a padding of $(p_\\textrm{h}, p_\\textrm{w})$ and a stride of $(s_\\textrm{h}, s_\\textrm{w})$.\n",
    "1. Why do you expect max-pooling and average pooling to work differently?\n",
    "1. Do we need a separate minimum pooling layer? Can you replace it with another operation?\n",
    "1. We could use the softmax operation for pooling. Why might it not be so popular?\n",
    "\n",
    "## 摘要\n",
    "\n",
    "池化是一个极其简单的操作。正如其名称所示，它在值窗口上聚合结果。所有卷积语义（如步幅和填充）的应用方式与之前相同。注意池化层对通道数保持不变，即它对每个通道单独作用。最后，在两种常用池化选择中，最大池化优于平均池化，因为它赋予输出一定程度的平移不变性。常见选择是采用$2 \\times 2$的池化窗口，将输出的空间分辨率缩小四分之一。\n",
    "\n",
    "需要注意的是，除了池化外还有许多降低分辨率的方法。例如，随机池化 :cite:`Zeiler.Fergus.2013` 和分数最大池化 :cite:`Graham.2014` 将聚合与随机化结合。这可以在某些情况下略微提高准确率。最后，正如我们稍后将在注意力机制中看到的，还有更精细的输出聚合方法，例如通过使用查询与表示向量之间的对齐。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 通过卷积实现平均池化\n",
    "1. 证明最大池化不能单独通过卷积实现\n",
    "1. 最大池化可以使用ReLU运算实现，即$\\textrm{ReLU}(x) = \\max(0, x)$\n",
    "    1. 仅使用ReLU运算表达$\\max (a, b)$\n",
    "    1. 通过卷积和ReLU层实现最大池化\n",
    "    1. 对于$2 \\times 2$卷积需要多少通道和层？$3 \\times 3$卷积呢？\n",
    "1. 池化层的计算成本是多少？假设池化层输入大小为$c\\times h\\times w$，池化窗口形状为$p_\\textrm{h}\\times p_\\textrm{w}$，填充为$(p_\\textrm{h}, p_\\textrm{w})$，步幅为$(s_\\textrm{h}, s_\\textrm{w})$\n",
    "1. 为什么最大池化和平均池化效果不同？\n",
    "1. 是否需要单独的最小池化层？可以用其他操作代替吗？\n",
    "1. 可以使用softmax运算进行池化，为什么它不太流行？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8223740",
   "metadata": {
    "origin_pos": 44,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/72)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
