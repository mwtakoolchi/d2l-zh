{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8746e745",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Padding and Stride\n",
    ":label:`sec_padding`\n",
    "\n",
    "Recall the example of a convolution in :numref:`fig_correlation`. \n",
    "The input had both a height and width of 3\n",
    "and the convolution kernel had both a height and width of 2,\n",
    "yielding an output representation with dimension $2\\times2$.\n",
    "Assuming that the input shape is $n_\\textrm{h}\\times n_\\textrm{w}$\n",
    "and the convolution kernel shape is $k_\\textrm{h}\\times k_\\textrm{w}$,\n",
    "the output shape will be $(n_\\textrm{h}-k_\\textrm{h}+1) \\times (n_\\textrm{w}-k_\\textrm{w}+1)$: \n",
    "we can only shift the convolution kernel so far until it runs out\n",
    "of pixels to apply the convolution to. \n",
    "\n",
    "In the following we will explore a number of techniques, \n",
    "including padding and strided convolutions,\n",
    "that offer more control over the size of the output. \n",
    "As motivation, note that since kernels generally\n",
    "have width and height greater than $1$,\n",
    "after applying many successive convolutions,\n",
    "we tend to wind up with outputs that are\n",
    "considerably smaller than our input.\n",
    "If we start with a $240 \\times 240$ pixel image,\n",
    "ten layers of $5 \\times 5$ convolutions\n",
    "reduce the image to $200 \\times 200$ pixels,\n",
    "slicing off $30 \\%$ of the image and with it\n",
    "obliterating any interesting information\n",
    "on the boundaries of the original image.\n",
    "*Padding* is the most popular tool for handling this issue.\n",
    "In other cases, we may want to reduce the dimensionality drastically,\n",
    "e.g., if we find the original input resolution to be unwieldy.\n",
    "*Strided convolutions* are a popular technique that can help in these instances.\n",
    "\n",
    "## 填充与步幅\n",
    ":label:`sec_padding`\n",
    "\n",
    "回忆 :numref:`fig_correlation` 中的卷积运算示例。输入的高宽均为3，卷积核的高宽均为2，得到$2\\times2$的输出。假设输入形状为$n_\\textrm{h}\\times n_\\textrm{w}$，卷积核形状为$k_\\textrm{h}\\times k_\\textrm{w}$，则输出形状为$(n_\\textrm{h}-k_\\textrm{h}+1) \\times (n_\\textrm{w}-k_\\textrm{w}+1)$：我们只能在有效像素范围内滑动卷积核。\n",
    "\n",
    "以下我们将探讨填充（padding）和步幅（stride）等技术，它们能更精细地控制输出尺寸。\n",
    "\n",
    "### 填充\n",
    "当应用多层连续卷积时，输出尺寸缩减会导致边界信息丢失。例如$240 \\times 240$图像经过10层$5 \\times 5$卷积后，尺寸会缩减至$200 \\times 200$，损失30%的边界信息。填充是解决这一问题的常用方法。\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[输入] --> B[填充]\n",
    "    B --> C[卷积运算]\n",
    "    C --> D[保持尺寸的输出]\n",
    "    \n",
    "    style A fill:#e6f3ff,stroke:#333\n",
    "    style B fill:#ffe6e6,stroke:#333\n",
    "    style C fill:#e6ffe6,stroke:#333\n",
    "    style D fill:#f0f0f0,stroke:#333\n",
    "```\n",
    "\n",
    "数学表达：  \n",
    "对输入$(n_h, n_w)$进行$p_h$行高填充和$p_w$列宽填充后，输出形状变为：\n",
    "$$(n_h - k_h + p_h + 1) \\times (n_w - k_w + p_w + 1)$$\n",
    "\n",
    "常见填充方式：\n",
    "- 零填充：用0填充边界\n",
    "- 镜像填充：复制边界镜像值\n",
    "- 周期性填充：重复输入特征\n",
    "\n",
    "### 步幅\n",
    "当需要大幅降维时，步幅能有效控制卷积核滑动间隔。步幅$s_h$和$s_w$分别表示高度和宽度方向的滑动步长。\n",
    "\n",
    "输出尺寸计算公式：\n",
    "$$\\left\\lfloor(n_h - k_h + p_h + s_h)/s_h\\right\\rfloor \\times \\left\\lfloor(n_w - k_w + p_w + s_w)/s_w\\right\\rfloor$$\n",
    "\n",
    "示例对比：\n",
    "| 参数设置 | 输入尺寸 | 输出尺寸 | 计算量缩减 |\n",
    "|---------|---------|---------|----------|\n",
    "| stride=1 | 224x224 | 224x224 | 基准     |\n",
    "| stride=2 | 224x224 | 112x112 | 75%      |\n",
    "| stride=4 | 224x224 | 56x56   | 93.75%   |\n",
    "\n",
    "```python\n",
    "# PyTorch实现示例\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=64, \n",
    "                kernel_size=3, stride=2, padding=1)\n",
    "# padding=1保持尺寸减半时的边界信息完整性\n",
    "```\n",
    "\n",
    "### 组合应用\n",
    "现代CNN架构典型配置：\n",
    "- 浅层使用小步幅（1-2）保持细节\n",
    "- 深层使用大步幅（2）进行特征抽象\n",
    "- 配合池化操作构建层次化特征\n",
    "\n",
    "这种设计平衡了：\n",
    "1. 特征分辨率保持\n",
    "2. 感受野扩展\n",
    "3. 计算效率优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1e93ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:11.651657Z",
     "iopub.status.busy": "2023-08-18T07:09:11.651119Z",
     "iopub.status.idle": "2023-08-18T07:09:13.536667Z",
     "shell.execute_reply": "2023-08-18T07:09:13.535729Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0652bea",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## Padding\n",
    "\n",
    "As described above, one tricky issue when applying convolutional layers\n",
    "is that we tend to lose pixels on the perimeter of our image. Consider :numref:`img_conv_reuse` that depicts the pixel utilization as a function of the convolution kernel size and the position within the image. The pixels in the corners are hardly used at all. \n",
    "\n",
    "![Pixel utilization for convolutions of size $1 \\times 1$, $2 \\times 2$, and $3 \\times 3$ respectively.](../img/conv-reuse.svg)\n",
    ":label:`img_conv_reuse`\n",
    "\n",
    "Since we typically use small kernels,\n",
    "for any given convolution\n",
    "we might only lose a few pixels\n",
    "but this can add up as we apply\n",
    "many successive convolutional layers.\n",
    "One straightforward solution to this problem\n",
    "is to add extra pixels of filler around the boundary of our input image,\n",
    "thus increasing the effective size of the image.\n",
    "Typically, we set the values of the extra pixels to zero.\n",
    "In :numref:`img_conv_pad`, we pad a $3 \\times 3$ input,\n",
    "increasing its size to $5 \\times 5$.\n",
    "The corresponding output then increases to a $4 \\times 4$ matrix.\n",
    "The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+0\\times1+0\\times2+0\\times3=0$.\n",
    "\n",
    "![Two-dimensional cross-correlation with padding.](../img/conv-pad.svg)\n",
    ":label:`img_conv_pad`\n",
    "\n",
    "In general, if we add a total of $p_\\textrm{h}$ rows of padding\n",
    "(roughly half on top and half on bottom)\n",
    "and a total of $p_\\textrm{w}$ columns of padding\n",
    "(roughly half on the left and half on the right),\n",
    "the output shape will be\n",
    "\n",
    "$$(n_\\textrm{h}-k_\\textrm{h}+p_\\textrm{h}+1)\\times(n_\\textrm{w}-k_\\textrm{w}+p_\\textrm{w}+1).$$\n",
    "\n",
    "This means that the height and width of the output\n",
    "will increase by $p_\\textrm{h}$ and $p_\\textrm{w}$, respectively.\n",
    "\n",
    "In many cases, we will want to set $p_\\textrm{h}=k_\\textrm{h}-1$ and $p_\\textrm{w}=k_\\textrm{w}-1$\n",
    "to give the input and output the same height and width.\n",
    "This will make it easier to predict the output shape of each layer\n",
    "when constructing the network.\n",
    "Assuming that $k_\\textrm{h}$ is odd here,\n",
    "we will pad $p_\\textrm{h}/2$ rows on both sides of the height.\n",
    "If $k_\\textrm{h}$ is even, one possibility is to\n",
    "pad $\\lceil p_\\textrm{h}/2\\rceil$ rows on the top of the input\n",
    "and $\\lfloor p_\\textrm{h}/2\\rfloor$ rows on the bottom.\n",
    "We will pad both sides of the width in the same way.\n",
    "\n",
    "CNNs commonly use convolution kernels\n",
    "with odd height and width values, such as 1, 3, 5, or 7.\n",
    "Choosing odd kernel sizes has the benefit\n",
    "that we can preserve the dimensionality\n",
    "while padding with the same number of rows on top and bottom,\n",
    "and the same number of columns on left and right.\n",
    "\n",
    "Moreover, this practice of using odd kernels\n",
    "and padding to precisely preserve dimensionality\n",
    "offers a clerical benefit.\n",
    "For any two-dimensional tensor `X`,\n",
    "when the kernel's size is odd\n",
    "and the number of padding rows and columns\n",
    "on all sides are the same,\n",
    "thereby producing an output with the same height and width as the input,\n",
    "we know that the output `Y[i, j]` is calculated\n",
    "by cross-correlation of the input and convolution kernel\n",
    "with the window centered on `X[i, j]`.\n",
    "\n",
    "In the following example, we create a two-dimensional convolutional layer\n",
    "with a height and width of 3\n",
    "and (**apply 1 pixel of padding on all sides.**)\n",
    "Given an input with a height and width of 8,\n",
    "we find that the height and width of the output is also 8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef443e20",
   "metadata": {},
   "source": [
    "## 填充\n",
    "\n",
    "如前面所述，应用卷积层时容易丢失图像边缘的像素。参考 :numref:`img_conv_reuse` 中不同卷积核尺寸对像素利用率的可视化，可以看到角落像素的利用率最低。\n",
    "\n",
    "![$1 \\times 1$、$2 \\times 2$ 和 $3 \\times 3$ 卷积核的像素利用率示意图](../img/conv-reuse.svg)\n",
    ":label:`img_conv_reuse`\n",
    "\n",
    "### 填充机制\n",
    "为解决边界信息丢失问题，常用方法是在输入图像周围添加填充元素（通常用零填充）。如 :numref:`img_conv_pad` 所示，将$3 \\times 3$输入填充为$5 \\times 5$，输出尺寸相应增加到$4 \\times 4$。阴影部分展示了第一个输出元素的计算过程：$0×0+0×1+0×2+0×3=0$。\n",
    "\n",
    "![带填充的二维互相关运算](../img/conv-pad.svg)\n",
    ":label:`img_conv_pad`\n",
    "\n",
    "数学表达式：\n",
    "当添加$p_\\textrm{h}$行高填充和$p_\\textrm{w}$列宽填充时，输出尺寸变为：\n",
    "$$(n_\\textrm{h}-k_\\textrm{h}+p_\\textrm{h}+1)\\times(n_\\textrm{w}-k_\\textrm{w}+p_\\textrm{w}+1)$$\n",
    "\n",
    "### 填充策略\n",
    "常用配置方案：\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[输入尺寸n×n] --> B{卷积核奇偶性}\n",
    "    B -->|奇数核k| C[对称填充(p-1)/2]\n",
    "    B -->|偶数核k| D[非对称填充⌈p/2⌉与⌊p/2⌋]\n",
    "    C --> E[保持尺寸n×n]\n",
    "    D --> F[尺寸变化]\n",
    "```\n",
    "\n",
    "典型配置：\n",
    "- 当$k_h$为奇数时，设置$p_h = k_h - 1$（高度方向总填充）\n",
    "- 当$k_w$为奇数时，设置$p_w = k_w - 1$（宽度方向总填充）\n",
    "\n",
    "### 奇数核优势\n",
    "CNN常用奇数尺寸卷积核（1/3/5/7）的原因：\n",
    "1. 对称填充：可均匀分配填充量到各边\n",
    "2. 中心定位：输出元素Y[i,j]对应输入X[i,j]为中心的窗口\n",
    "3. 尺寸保持：输入输出尺寸一致，便于网络设计\n",
    "\n",
    "### 代码示例\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义带填充的卷积层\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, padding=1)  # 3×3核，1像素填充\n",
    "\n",
    "# 验证尺寸保持\n",
    "X = torch.rand(size=(8, 8)).reshape(1, 1, 8, 8)\n",
    "Y = conv(X)\n",
    "print(Y.shape)  # 输出 torch.Size([1, 1, 8, 8])\n",
    "```\n",
    "\n",
    "### 工程实践建议\n",
    "1. 对于浅层网络，优先使用3×3卷积核配合1像素填充\n",
    "2. 深层网络可交替使用5×5和3×3卷积核\n",
    "3. 使用7×7卷积核时需注意计算量激增问题\n",
    "4. 偶数核尺寸仅在特殊需求时使用（如需要非对称感受野）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f733253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:13.540698Z",
     "iopub.status.busy": "2023-08-18T07:09:13.540158Z",
     "iopub.status.idle": "2023-08-18T07:09:13.588177Z",
     "shell.execute_reply": "2023-08-18T07:09:13.587160Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We define a helper function to calculate convolutions. It initializes the\n",
    "# convolutional layer weights and performs corresponding dimensionality\n",
    "# elevations and reductions on the input and output\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
    "# are added\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa412d52",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "When the height and width of the convolution kernel are different,\n",
    "we can make the output and input have the same height and width\n",
    "by [**setting different padding numbers for height and width.**]\n",
    "\n",
    "当卷积核的高度和宽度不同时，我们可以通过以下方式使输出与输入保持相同尺寸：\n",
    "【通过为高度和宽度分别设置不同的填充值】。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ff32fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:13.593762Z",
     "iopub.status.busy": "2023-08-18T07:09:13.592844Z",
     "iopub.status.idle": "2023-08-18T07:09:13.605804Z",
     "shell.execute_reply": "2023-08-18T07:09:13.604686Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a convolution kernel with height 5 and width 3. The padding on either\n",
    "# side of the height and width are 2 and 1, respectively\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7534a",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## Stride\n",
    "\n",
    "When computing the cross-correlation,\n",
    "we start with the convolution window\n",
    "at the upper-left corner of the input tensor,\n",
    "and then slide it over all locations both down and to the right.\n",
    "In the previous examples, we defaulted to sliding one element at a time.\n",
    "However, sometimes, either for computational efficiency\n",
    "or because we wish to downsample,\n",
    "we move our window more than one element at a time,\n",
    "skipping the intermediate locations. This is particularly useful if the convolution \n",
    "kernel is large since it captures a large area of the underlying image.\n",
    "\n",
    "We refer to the number of rows and columns traversed per slide as *stride*.\n",
    "So far, we have used strides of 1, both for height and width.\n",
    "Sometimes, we may want to use a larger stride.\n",
    ":numref:`img_conv_stride` shows a two-dimensional cross-correlation operation\n",
    "with a stride of 3 vertically and 2 horizontally.\n",
    "The shaded portions are the output elements as well as the input and kernel tensor elements used for the output computation: $0\\times0+0\\times1+1\\times2+2\\times3=8$, $0\\times0+6\\times1+0\\times2+0\\times3=6$.\n",
    "We can see that when the second element of the first column is generated,\n",
    "the convolution window slides down three rows.\n",
    "The convolution window slides two columns to the right\n",
    "when the second element of the first row is generated.\n",
    "When the convolution window continues to slide two columns to the right on the input,\n",
    "there is no output because the input element cannot fill the window\n",
    "(unless we add another column of padding).\n",
    "\n",
    "![Cross-correlation with strides of 3 and 2 for height and width, respectively.](../img/conv-stride.svg)\n",
    ":label:`img_conv_stride`\n",
    "\n",
    "In general, when the stride for the height is $s_\\textrm{h}$\n",
    "and the stride for the width is $s_\\textrm{w}$, the output shape is\n",
    "\n",
    "$$\\lfloor(n_\\textrm{h}-k_\\textrm{h}+p_\\textrm{h}+s_\\textrm{h})/s_\\textrm{h}\\rfloor \\times \\lfloor(n_\\textrm{w}-k_\\textrm{w}+p_\\textrm{w}+s_\\textrm{w})/s_\\textrm{w}\\rfloor.$$\n",
    "\n",
    "If we set $p_\\textrm{h}=k_\\textrm{h}-1$ and $p_\\textrm{w}=k_\\textrm{w}-1$,\n",
    "then the output shape can be simplified to\n",
    "$\\lfloor(n_\\textrm{h}+s_\\textrm{h}-1)/s_\\textrm{h}\\rfloor \\times \\lfloor(n_\\textrm{w}+s_\\textrm{w}-1)/s_\\textrm{w}\\rfloor$.\n",
    "Going a step further, if the input height and width\n",
    "are divisible by the strides on the height and width,\n",
    "then the output shape will be $(n_\\textrm{h}/s_\\textrm{h}) \\times (n_\\textrm{w}/s_\\textrm{w})$.\n",
    "\n",
    "Below, we [**set the strides on both the height and width to 2**],\n",
    "thus halving the input height and width.\n",
    "\n",
    "\n",
    "## 步幅\n",
    "\n",
    "在进行互相关运算时，我们默认从输入张量的左上角开始滑动卷积窗口。当需要控制特征图下采样率或提升计算效率时，可以通过调整步幅(stride)参数实现窗口跳跃式滑动。\n",
    "\n",
    "### 核心概念\n",
    "- **步幅定义**：窗口每次滑动的行数和列数，分别称为垂直步幅(s_ℎ)和水平步幅(s_w)\n",
    "- **默认值**：s_ℎ=1, s_w=1\n",
    "- **下采样效应**：步幅加倍可使输出空间维度减半\n",
    "\n",
    "### 步幅为(3,2)的示例分析\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[输入张量] --> B[第一次窗口位置]\n",
    "    B --> C[计算输出8]\n",
    "    A --> D[垂直下移3行]\n",
    "    D --> E[第二次窗口位置]\n",
    "    E --> F[计算输出6]\n",
    "    A --> G[水平右移2列]\n",
    "    G --> H[边界终止条件]\n",
    "    \n",
    "    style A fill:#e6f3ff,stroke:#333\n",
    "    style B fill:#ffe6e6,stroke:#333\n",
    "    style C fill:#e6ffe6,stroke:#333\n",
    "    style D fill:#ffebcc,stroke:#333\n",
    "```\n",
    "\n",
    "### 输出形状计算公式\n",
    "当设置填充数p_ℎ, p_w时，输出尺寸为：\n",
    "$$ \n",
    "\\left\\lfloor \\frac{n_ℎ - k_ℎ + p_ℎ + s_ℎ}{s_ℎ} \\right\\rfloor \\times \n",
    "\\left\\lfloor \\frac{n_w - k_w + p_w + s_w}{s_w} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "### 特殊情形推导\n",
    "当采用全填充策略时（p_ℎ=k_ℎ-1, p_w=k_w-1）：\n",
    "$$\n",
    "\\text{输出尺寸} = \n",
    "\\left\\lfloor \\frac{n_ℎ + s_ℎ -1}{s_ℎ} \\right\\rfloor \\times \n",
    "\\left\\lfloor \\frac{n_w + s_w -1}{s_w} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "### 最佳实践\n",
    "当输入尺寸能被步幅整除时：\n",
    "```python\n",
    "# 输入尺寸256x256，卷积核3x3，步幅2x2\n",
    "output_shape = (256//2, 256//2)  # 输出128x128\n",
    "```\n",
    "\n",
    "### 参数配置表\n",
    "| 输入尺寸 | 卷积核 | 步幅 | 输出尺寸 |\n",
    "|---------|--------|------|---------|\n",
    "| 224x224 | 3x3    | 2x2  | 112x112 |\n",
    "| 112x112 | 5x5    | 3x3  | 37x37   |\n",
    "| 512x512 | 7x7    | 4x4  | 128x128 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0c04c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:13.610175Z",
     "iopub.status.busy": "2023-08-18T07:09:13.609896Z",
     "iopub.status.idle": "2023-08-18T07:09:13.630721Z",
     "shell.execute_reply": "2023-08-18T07:09:13.626763Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04314794",
   "metadata": {},
   "source": [
    "对于给定的卷积层配置 `nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)`，输出尺寸计算如下：\n",
    "\n",
    "### 计算公式\n",
    "$$ \n",
    "n_{out} = \\left\\lfloor \\frac{n_{in} + 2p - k}{s} \\right\\rfloor + 1\n",
    "$$\n",
    "其中：\n",
    "- $n_{in}$：输入尺寸（高/宽）\n",
    "- $p=1$：单边填充量\n",
    "- $k=3$：卷积核尺寸\n",
    "- $s=2$：步幅\n",
    "\n",
    "### 计算实例\n",
    "假设输入特征图尺寸为 5×5：\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "input = torch.randn(1, 3, 5, 5)  # (batch, channels, height, width)\n",
    "output = conv(input)\n",
    "print(output.shape)  # 输出 torch.Size([1, 1, 3, 3])\n",
    "```\n",
    "\n",
    "推导过程：\n",
    "$$ \n",
    "n_{out} = \\left\\lfloor \\frac{5 + 2×1 - 3}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{4}{2} \\right\\rfloor + 1 = 3\n",
    "$$\n",
    "\n",
    "### 尺寸对照表\n",
    "| 输入尺寸 | 输出尺寸 | 计算步骤 |\n",
    "|---------|---------|---------|\n",
    "| 5×5     | 3×3     | (5+2-3)/2=2 → 2+1=3 |\n",
    "| 7×7     | 4×4     | (7+2-3)/2=3 → 3+1=4 |\n",
    "| 6×6     | 3×3     | (6+2-3)/2=2.5 → 2+1=3 |\n",
    "| 4×4     | 2×2     | (4+2-3)/2=1.5 → 1+1=2 |\n",
    "\n",
    "### 特殊情形验证\n",
    "当输入尺寸为偶数时：\n",
    "```python\n",
    "input = torch.randn(1, 3, 6, 6)\n",
    "output = conv(input)\n",
    "print(output.shape)  # 输出 torch.Size([1, 1, 3, 3]) \n",
    "# 计算：(6+2-3)/2=2.5 → floor(2.5)=2 → 2+1=3\n",
    "```\n",
    "\n",
    "### 可视化计算流程\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[输入5x5] --> B[填充后7x7]\n",
    "    B --> C[3x3卷积核]\n",
    "    C --> D[步长2滑动]\n",
    "    D --> E[输出3x3]\n",
    "    \n",
    "    style A fill:#e6f3ff,stroke:#333\n",
    "    style B fill:#ffe6e6,stroke:#333\n",
    "    style C fill:#e6ffe6,stroke:#333\n",
    "    style D fill:#ffebcc,stroke:#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c535b",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "Let's look at (**a slightly more complicated example**).\n",
    "\n",
    "我们看看一个稍微复杂的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32aba067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:09:13.636530Z",
     "iopub.status.busy": "2023-08-18T07:09:13.635736Z",
     "iopub.status.idle": "2023-08-18T07:09:13.646915Z",
     "shell.execute_reply": "2023-08-18T07:09:13.645901Z"
    },
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cdc1dd",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## Summary and Discussion\n",
    "\n",
    "Padding can increase the height and width of the output. This is often used to give the output the same height and width as the input to avoid undesirable shrinkage of the output. Moreover, it ensures that all pixels are used equally frequently. Typically we pick symmetric padding on both sides of the input height and width. In this case we refer to $(p_\\textrm{h}, p_\\textrm{w})$ padding. Most commonly we set $p_\\textrm{h} = p_\\textrm{w}$, in which case we simply state that we choose padding $p$. \n",
    "\n",
    "A similar convention applies to strides. When horizontal stride $s_\\textrm{h}$ and vertical stride $s_\\textrm{w}$ match, we simply talk about stride $s$. The stride can reduce the resolution of the output, for example reducing the height and width of the output to only $1/n$ of the height and width of the input for $n > 1$. By default, the padding is 0 and the stride is 1. \n",
    "\n",
    "So far all padding that we discussed simply extended images with zeros. This has significant computational benefit since it is trivial to accomplish. Moreover, operators can be engineered to take advantage of this padding implicitly without the need to allocate additional memory. At the same time, it allows CNNs to encode implicit position information within an image, simply by learning where the \"whitespace\" is. There are many alternatives to zero-padding. :citet:`Alsallakh.Kokhlikyan.Miglani.ea.2020` provided an extensive overview of those (albeit without a clear case for when to use nonzero paddings unless artifacts occur). \n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Given the final code example in this section with kernel size $(3, 5)$, padding $(0, 1)$, and stride $(3, 4)$, \n",
    "   calculate the output shape to check if it is consistent with the experimental result.\n",
    "1. For audio signals, what does a stride of 2 correspond to?\n",
    "1. Implement mirror padding, i.e., padding where the border values are simply mirrored to extend tensors. \n",
    "1. What are the computational benefits of a stride larger than 1?\n",
    "1. What might be statistical benefits of a stride larger than 1?\n",
    "1. How would you implement a stride of $\\frac{1}{2}$? What does it correspond to? When would this be useful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e18ba5",
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/68)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d80f5",
   "metadata": {},
   "source": [
    "### 练习题解答\n",
    "\n",
    "1. **输出形状验证**  \n",
    "输入尺寸假设为8×10：\n",
    "$$ \n",
    "h_{out} = \\lfloor (8 + 2×0 -3)/3 \\rfloor +1 = \\lfloor 5/3 \\rfloor +1 = 2 \\\\\n",
    "w_{out} = \\lfloor (10 + 2×1 -5)/4 \\rfloor +1 = \\lfloor 7/4 \\rfloor +1 = 2\n",
    "$$\n",
    "代码验证：\n",
    "```python\n",
    "conv = nn.Conv2d(1,1,kernel_size=(3,5),stride=(3,4),padding=(0,1))\n",
    "x = torch.randn(1,1,8,10)\n",
    "print(conv(x).shape)  # torch.Size([1,1,2,2])\n",
    "```\n",
    "\n",
    "2. **音频信号步幅含义**  \n",
    "音频信号处理时：\n",
    "- 时域步幅2 ⇒ 时间分辨率减半\n",
    "- 等效采样率：原采样率/2\n",
    "- 典型应用：时域下采样\n",
    "\n",
    "3. **镜像填充实现**  \n",
    "PyTorch实现方式：\n",
    "```python\n",
    "# 手动实现\n",
    "def mirror_pad(x, padding):\n",
    "    return torch.nn.functional.pad(x, padding, mode='reflect')\n",
    "\n",
    "# 卷积层应用\n",
    "conv = nn.Conv2d(3,16,kernel_size=3,padding=1,padding_mode='reflect')\n",
    "```\n",
    "\n",
    "4. **计算优势**  \n",
    "步幅>1的优势矩阵：\n",
    "| 因素 | 传统步幅1 | 步幅2 | 提升比例 |\n",
    "|-----|---------|------|---------|\n",
    "| 乘加操作 | O(n²k²) | O(n²k²/4) | 75% |\n",
    "| 内存占用 | H×W×C | (H/2)×(W/2)×C | 75% |\n",
    "| 层间通信 | 高 | 低 | - |\n",
    "\n",
    "5. **统计优势**  \n",
    "- 增强平移不变性\n",
    "- 降低过拟合风险（感受野增大）\n",
    "- 特征响应更鲁棒（MaxPooling类似效果）\n",
    "\n",
    "6. **分数步幅实现**  \n",
    "实现方法：\n",
    "```python\n",
    "# 使用转置卷积实现\n",
    "conv = nn.ConvTranspose2d(3,3,kernel_size=3,stride=2,padding=1)\n",
    "```\n",
    "应用场景：\n",
    "- 图像超分辨率重建\n",
    "- 语义分割上采样\n",
    "- GAN生成高分辨率图像"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
